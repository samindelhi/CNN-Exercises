{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhGwmfcrwkBgSOHQnP7kpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samindelhi/CNN-Exercises/blob/main/Yolo11_Transfer_learning_With_Correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo11 Transfer Learning With Correction\n"
      ],
      "metadata": {
        "id": "jFGergbWPu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER3Ai9F0QI1L",
        "outputId": "847d1b71-4eb3-4e33-968a-0a8cc70637af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.214-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.214-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.214 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BkiumRrYPa1d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.data.dataset import ClassificationDataset\n",
        "from ultralytics.models.yolo.classify import ClassificationTrainer, ClassificationValidator, ClassificationPredictor\n",
        "\n",
        "class CustomizedDataset(ClassificationDataset):\n",
        "  \"\"\" A Customized dataset class for image classification with enhanced data augmentation transforms\"\"\"\n",
        "\n",
        "  def __init__(self, root:str, args, augment:bool=False, prefix:str=\"\"):\n",
        "    \"\"\"Initialize a customised classificaiton dataset with enhanced data augmentation transforms.\"\"\"\n",
        "    super().__init__(root, args, augment, prefix)\n",
        "    train_transforms = T.Compose(\n",
        "        [\n",
        "            T.Resize((args.imgsz, args.imgsz)),\n",
        "            T.RandomHorizontalFlip(p=args.fliplr),\n",
        "            T.RandomVerticalFlip(p=args.flipud),\n",
        "            T.RandAugment(interpolation=T.InterpolationMode.BILINEAR),\n",
        "            T.ColorJitter(\n",
        "                brightness=args.hsv_v,\n",
        "                contrast=args.hsv_v,\n",
        "                saturation=args.hsv_s,\n",
        "                hue=args.hsv_h\n",
        "            ),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=torch.tensor(0), std=torch.tensor(1)),\n",
        "            T.RandomErasing(p=args.erasing, inplace=True)]\n",
        "    )\n",
        "    # Add your custom validation transforms here\n",
        "    val_transforms = T.Compose(\n",
        "        [\n",
        "            T.Resize((args.imgsz, args.imgsz)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=torch.tensor(0), std=torch.tensor(1)),\n",
        "        ]\n",
        "    )\n",
        "    self.torch_transforms = train_transforms if augment else val_transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomizedTrainer(ClassificationTrainer):\n",
        "    \"\"\"A customized trainer class for YOLO classification models with enhanced dataset handling.\"\"\"\n",
        "\n",
        "    def build_dataset(self, img_path: str, mode: str = \"train\", batch=None):\n",
        "        \"\"\"Build a customized dataset for classification training and the validation during training.\"\"\"\n",
        "        return CustomizedDataset(root=img_path, args=self.args, augment=mode == \"train\", prefix=mode)\n",
        "\n",
        "\n",
        "class CustomizedValidator(ClassificationValidator):\n",
        "    \"\"\"A customized validator class for YOLO classification models with enhanced dataset handling.\"\"\"\n",
        "\n",
        "    def build_dataset(self, img_path: str, mode: str = \"train\"):\n",
        "        \"\"\"Build a customized dataset for classification standalone validation.\"\"\"\n",
        "        return CustomizedDataset(root=img_path, args=self.args, augment=mode == \"train\", prefix=self.args.split)\n",
        "\n",
        "\n",
        "model = YOLO(\"yolo11n-cls.pt\")\n",
        "model.train(data=\"imagenet1000\", trainer=CustomizedTrainer, epochs=10, imgsz=224, batch=64)\n",
        "model.val(data=\"imagenet1000\", validator=CustomizedValidator, imgsz=224, batch=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5AtlIqBTE8V",
        "outputId": "3965ac75-f7aa-4946-ef55-bdf5ad94bd51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=imagenet1000, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenet1000/train... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenet1000/val... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=80 with nc=1000\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1   1611240  ultralytics.nn.modules.head.Classify         [256, 1000]                   \n",
            "YOLO11n-cls summary: 86 layers, 2,812,104 parameters, 2,812,104 gradients, 4.3 GFLOPs\n",
            "Transferred 236/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 196.7Â±129.0 MB/s, size: 2.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/imagenet1000/train... 1002 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1002/1002 2.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 84.9Â±47.2 MB/s, size: 2.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/imagenet1000/val... 1002 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1002/1002 2.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1e-05, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 16.7MB/s 0.0s\n",
            "\u001b[K       1/10     0.959G      2.534         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.8it/s 4.3s\n",
            "                   all      0.488      0.768\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/10      1.16G      2.533         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 3.7it/s 4.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 16.3it/s 0.5s\n",
            "                   all      0.496      0.769\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/10      1.17G      2.465         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.8it/s 9.1s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 20.5it/s 0.4s\n",
            "                   all        0.5      0.776\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/10      1.18G       2.47         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.6it/s 9.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 21.1it/s 0.4s\n",
            "                   all      0.502      0.773\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/10      1.19G      2.373         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.7it/s 9.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 21.2it/s 0.4s\n",
            "                   all      0.503      0.778\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/10       1.2G      2.417         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.6it/s 9.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 21.4it/s 0.4s\n",
            "                   all      0.502      0.778\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/10       1.2G      2.412         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.6it/s 10.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 14.9it/s 0.5s\n",
            "                   all      0.501      0.776\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/10      1.21G      2.372         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.7it/s 9.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 20.7it/s 0.4s\n",
            "                   all      0.504      0.777\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/10      1.22G      2.343         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.7it/s 9.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 21.0it/s 0.4s\n",
            "                   all      0.502      0.779\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/10      1.23G      2.333         42        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.6it/s 9.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 27.3it/s 0.3s\n",
            "                   all      0.503      0.774\n",
            "\n",
            "10 epochs completed in 0.032 hours.\n",
            "Optimizer stripped from /content/runs/classify/train3/weights/last.pt, 5.8MB\n",
            "Optimizer stripped from /content/runs/classify/train3/weights/best.pt, 5.8MB\n",
            "\n",
            "Validating /content/runs/classify/train3/weights/best.pt...\n",
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenet1000/train... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenet1000/val... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.5it/s 1.2s\n",
            "                   all      0.503      0.779\n",
            "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train3\u001b[0m\n",
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenet1000/train... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenet1000/val... found 1002 images in 1000 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 160.1Â±100.8 MB/s, size: 2.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/imagenet1000/val... 1002 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1002/1002 2.2Mit/s 0.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.9it/s 8.5s\n",
            "                   all      0.434      0.693\n",
            "Speed: 0.4ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7df9c2dda060>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.5633732676506042\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.4341317415237427, 'metrics/accuracy_top5': 0.6926147937774658, 'fitness': 0.5633732676506042}\n",
              "save_dir: PosixPath('/content/runs/classify/val')\n",
              "speed: {'preprocess': 0.3591832524953206, 'inference': 0.5528026696608183, 'loss': 0.00017929041923580625, 'postprocess': 0.00031769161682542016}\n",
              "task: 'classify'\n",
              "top1: 0.4341317415237427\n",
              "top5: 0.6926147937774658"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"1TCU1nqgIe1R_dW6LTkRxlufHlCCazyJl\"\n",
        "# Download destination filename\n",
        "output = \"myfile.zip\"\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MeOWJ7k5XbZZ",
        "outputId": "cce1ad52-994a-4ceb-9872-e87c480bf92a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TCU1nqgIe1R_dW6LTkRxlufHlCCazyJl\n",
            "From (redirected): https://drive.google.com/uc?id=1TCU1nqgIe1R_dW6LTkRxlufHlCCazyJl&confirm=t&uuid=8971e30c-8ef4-4c9e-ad9e-3f6b01a10123\n",
            "To: /content/myfile.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63.9M/63.9M [00:00<00:00, 149MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'myfile.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"myfile.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")"
      ],
      "metadata": {
        "id": "_-OFni51YfQ_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“ 2. Define paths (update with your dataset path)\n",
        "train_dir = \"/content/dataset/train\"\n",
        "val_dir = \"/content/dataset/valid\"\n",
        "img_size = 299\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "kXOFkCR8Yi29"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-cls.pt\")  # load an official model\n",
        "# model = YOLO(\"yolo11n.pt\")  # load a custom model\n",
        "model.train(data=\"/content/dataset/train\", trainer=CustomizedTrainer, epochs=10, imgsz=224, batch=64)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUC5ZNWdTOvH",
        "outputId": "9a2276dc-c7a7-4848-e469-9ea75bc4344d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset/train, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "WARNING âš ï¸ Dataset 'split=train' not found at /content/dataset/train/train\n",
            "Found 1275 images in subdirectories. Attempting to split...\n",
            "Splitting /content/dataset/train (2 classes, 1275 images) into 80% train, 20% val...\n",
            "Split complete in /content/dataset/train_split âœ…\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset/train_split/train... found 1019 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/dataset/train_split/val... found 256 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLO11n-cls summary: 86 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1060.1Â±277.8 MB/s, size: 35.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train_split/train... 1019 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1019/1019 5.9Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train_split/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 307.2Â±175.2 MB/s, size: 42.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/train_split/val... 256 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 256/256 2.7Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/train_split/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       1/10     0.742G       0.53         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.0it/s 15.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 22.9it/s 0.1s\n",
            "                   all      0.922          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/10     0.814G     0.1966         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.5it/s 10.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 23.6it/s 0.1s\n",
            "                   all      0.957          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/10     0.814G     0.1199         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 16.2it/s 0.1s\n",
            "                   all      0.945          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/10     0.816G     0.1276         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 24.3it/s 0.1s\n",
            "                   all      0.941          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/10     0.826G    0.08196         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 12.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 18.3it/s 0.1s\n",
            "                   all      0.945          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/10     0.834G     0.1023         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3it/s 12.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 27.4it/s 0.1s\n",
            "                   all      0.945          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/10     0.844G     0.1273         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 13.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 17.9it/s 0.1s\n",
            "                   all      0.941          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/10     0.852G    0.08479         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 13.1s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 24.9it/s 0.1s\n",
            "                   all      0.953          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/10     0.861G    0.05401         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.0it/s 15.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 19.5it/s 0.1s\n",
            "                   all      0.957          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/10     0.869G    0.04576         59        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.2it/s 13.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 17.3it/s 0.1s\n",
            "                   all      0.953          1\n",
            "\n",
            "10 epochs completed in 0.040 hours.\n",
            "Optimizer stripped from /content/runs/classify/train4/weights/last.pt, 3.2MB\n",
            "Optimizer stripped from /content/runs/classify/train4/weights/best.pt, 3.2MB\n",
            "\n",
            "Validating /content/runs/classify/train4/weights/best.pt...\n",
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 47 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=train' not found at /content/dataset/train/train\n",
            "Found 1275 images in subdirectories. Attempting to split...\n",
            "Splitting /content/dataset/train (2 classes, 1275 images) into 80% train, 20% val...\n",
            "Split complete in /content/dataset/train_split âœ…\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset/train_split/train... found 1214 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/dataset/train_split/val... found 451 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 16.3it/s 0.1s\n",
            "                   all      0.957          1\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train4\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7df9761cb8c0>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.978515625\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.95703125, 'metrics/accuracy_top5': 1.0, 'fitness': 0.978515625}\n",
              "save_dir: PosixPath('/content/runs/classify/train4')\n",
              "speed: {'preprocess': 0.05925074609347547, 'inference': 0.3078453554676841, 'loss': 8.326171840877805e-05, 'postprocess': 0.00016608593789158022}\n",
              "task: 'classify'\n",
              "top1: 0.95703125\n",
              "top5: 1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLI Implementation.Start training from a pretrained *.pt model.\n",
        "# !yolo classify train data=imagenet10 model=yolo11n-cls.pt epochs=5 imgsz=224\n"
      ],
      "metadata": {
        "id": "5MGTwZRoZQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(data=\"/content/dataset/valid\", validator=CustomizedValidator, imgsz=224, batch=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1faKRSlbZg8d",
        "outputId": "f2ce284b-f036-4bd7-c23b-072f00c49527"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 47 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=train' not found at /content/dataset/valid/train\n",
            "Found 364 images in subdirectories. Attempting to split...\n",
            "Splitting /content/dataset/valid (2 classes, 364 images) into 80% train, 20% val...\n",
            "Split complete in /content/dataset/valid_split âœ…\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset/valid_split/train... found 290 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/dataset/valid_split/val... found 74 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 880.9Â±268.5 MB/s, size: 25.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid_split/val... 74 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 74/74 5.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid_split/val.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.9it/s 2.2s\n",
            "                   all      0.851          1\n",
            "Speed: 1.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.top1, metrics.top5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9WtOFFfzzi",
        "outputId": "b673636c-fcf1-4372-9753-5e32b4af5d11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8513513803482056, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "# model = YOLO(\"yolo11n-cls.pt\")  # load an official model\n",
        "model = YOLO(\"/content/runs/classify/train4/weights/best.pt\")  # load a custom model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(\"/content/dataset/valid/daisy/14698531521_0c2f0c6539_jpg.rf.787d556676fe7d11fe3909353835a730.jpg\")  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A35aSwjgTj5q",
        "outputId": "92c0016c-f890-42fb-86d6-f100d972381a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/valid/daisy/14698531521_0c2f0c6539_jpg.rf.787d556676fe7d11fe3909353835a730.jpg: 224x224 daisy 1.00, dandelion 0.00, 5.0ms\n",
            "Speed: 4.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "585EK_ydTvIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}